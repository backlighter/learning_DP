{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe02cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 加载Fashion-MNIST数据集\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0532bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义softmax操作\n",
    "def softmax(X):\n",
    "    exps = torch.exp(X)\n",
    "    return exps / torch.sum(exps, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484a6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "def model(X):\n",
    "    logits = torch.matmul(X, w) + b\n",
    "    return softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff66765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义交叉熵损失函数\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    y_true = torch.LongTensor(y_true)\n",
    "    log_probs = -torch.log(y_pred.gather(1, y_true.view(-1, 1)))\n",
    "    return torch.mean(log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "657a4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义准确率计算函数\n",
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "    y_true = torch.LongTensor(y_true)\n",
    "    return torch.mean((y_pred == y_true).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7ae806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(epochs, learning_rate):\n",
    "    global w, b\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        for batch_images, batch_labels in train_dataloader:\n",
    "            batch_images = batch_images.reshape(-1, num_features)\n",
    "            \n",
    "            # 前向传播\n",
    "            y_pred = model(batch_images)\n",
    "            \n",
    "            # 计算损失和准确率\n",
    "            loss = cross_entropy(y_pred, batch_labels)\n",
    "            acc = accuracy(y_pred, batch_labels)\n",
    "            \n",
    "            # 反向传播和参数更新\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                w -= learning_rate * w.grad\n",
    "                b -= learning_rate * b.grad\n",
    "                w.grad.zero_()\n",
    "                b.grad.zero_()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += acc.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        avg_accuracy = total_accuracy / len(train_dataloader)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184ab00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义测试函数\n",
    "def test():\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_images, batch_labels in test_dataloader:\n",
    "            batch_images = batch_images.reshape(-1, num_features)\n",
    "            \n",
    "            # 前向传播\n",
    "            y_pred = model(batch_images)\n",
    "            \n",
    "            # 计算损失和准确率\n",
    "            loss = cross_entropy(y_pred, batch_labels)\n",
    "            acc = accuracy(y_pred, batch_labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += acc.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    avg_accuracy = total_accuracy / len(test_dataloader)\n",
    "    \n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f90f8a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.2780, Accuracy: 0.6116\n",
      "Epoch [2/50], Loss: 1.2286, Accuracy: 0.7329\n",
      "Epoch [3/50], Loss: 1.0433, Accuracy: 0.7605\n",
      "Epoch [4/50], Loss: 0.9429, Accuracy: 0.7751\n",
      "Epoch [5/50], Loss: 0.8732, Accuracy: 0.7845\n",
      "Epoch [6/50], Loss: 0.8232, Accuracy: 0.7929\n",
      "Epoch [7/50], Loss: 0.7823, Accuracy: 0.7985\n",
      "Epoch [8/50], Loss: 0.7500, Accuracy: 0.8034\n",
      "Epoch [9/50], Loss: 0.7217, Accuracy: 0.8070\n",
      "Epoch [10/50], Loss: 0.6973, Accuracy: 0.8099\n",
      "Epoch [11/50], Loss: 0.6771, Accuracy: 0.8131\n",
      "Epoch [12/50], Loss: 0.6583, Accuracy: 0.8156\n",
      "Epoch [13/50], Loss: 0.6418, Accuracy: 0.8180\n",
      "Epoch [14/50], Loss: 0.6272, Accuracy: 0.8205\n",
      "Epoch [15/50], Loss: 0.6145, Accuracy: 0.8225\n",
      "Epoch [16/50], Loss: 0.6025, Accuracy: 0.8230\n",
      "Epoch [17/50], Loss: 0.5914, Accuracy: 0.8259\n",
      "Epoch [18/50], Loss: 0.5819, Accuracy: 0.8256\n",
      "Epoch [19/50], Loss: 0.5719, Accuracy: 0.8274\n",
      "Epoch [20/50], Loss: 0.5640, Accuracy: 0.8296\n",
      "Epoch [21/50], Loss: 0.5568, Accuracy: 0.8306\n",
      "Epoch [22/50], Loss: 0.5485, Accuracy: 0.8324\n",
      "Epoch [23/50], Loss: 0.5428, Accuracy: 0.8328\n",
      "Epoch [24/50], Loss: 0.5362, Accuracy: 0.8335\n",
      "Epoch [25/50], Loss: 0.5282, Accuracy: 0.8360\n",
      "Epoch [26/50], Loss: 0.5228, Accuracy: 0.8369\n",
      "Epoch [27/50], Loss: 0.5186, Accuracy: 0.8365\n",
      "Epoch [28/50], Loss: 0.5132, Accuracy: 0.8382\n",
      "Epoch [29/50], Loss: 0.5077, Accuracy: 0.8385\n",
      "Epoch [30/50], Loss: 0.5039, Accuracy: 0.8390\n",
      "Epoch [31/50], Loss: 0.4993, Accuracy: 0.8413\n",
      "Epoch [32/50], Loss: 0.4950, Accuracy: 0.8411\n",
      "Epoch [33/50], Loss: 0.4926, Accuracy: 0.8416\n",
      "Epoch [34/50], Loss: 0.4867, Accuracy: 0.8438\n",
      "Epoch [35/50], Loss: 0.4835, Accuracy: 0.8431\n",
      "Epoch [36/50], Loss: 0.4797, Accuracy: 0.8450\n",
      "Epoch [37/50], Loss: 0.4764, Accuracy: 0.8448\n",
      "Epoch [38/50], Loss: 0.4742, Accuracy: 0.8458\n",
      "Epoch [39/50], Loss: 0.4716, Accuracy: 0.8468\n",
      "Epoch [40/50], Loss: 0.4691, Accuracy: 0.8462\n",
      "Epoch [41/50], Loss: 0.4673, Accuracy: 0.8475\n",
      "Epoch [42/50], Loss: 0.4641, Accuracy: 0.8470\n",
      "Epoch [43/50], Loss: 0.4611, Accuracy: 0.8479\n",
      "Epoch [44/50], Loss: 0.4583, Accuracy: 0.8485\n",
      "Epoch [45/50], Loss: 0.4580, Accuracy: 0.8485\n",
      "Epoch [46/50], Loss: 0.4543, Accuracy: 0.8492\n",
      "Epoch [47/50], Loss: 0.4532, Accuracy: 0.8504\n",
      "Epoch [48/50], Loss: 0.4522, Accuracy: 0.8498\n",
      "Epoch [49/50], Loss: 0.4481, Accuracy: 0.8504\n",
      "Epoch [50/50], Loss: 0.4471, Accuracy: 0.8514\n",
      "Test Loss: 0.5279, Test Accuracy: 0.8316\n"
     ]
    }
   ],
   "source": [
    "# 下载训练集和测试集\n",
    "train_dataset = FashionMNIST(root='data/', train=True, transform=ToTensor(), download=True)\n",
    "test_dataset = FashionMNIST(root='data/', train=False, transform=ToTensor(), download=True)\n",
    "\n",
    "# 创建训练集和测试集的数据加载器\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# 初始化模型参数\n",
    "num_features = 28 * 28  # 输入特征的数量（图像大小为28x28）\n",
    "num_classes = 10  # 类别数量\n",
    "w = torch.randn(num_features, num_classes, requires_grad=True)\n",
    "b = torch.zeros(num_classes, requires_grad=True)\n",
    "# 设置训练参数并开始训练\n",
    "epochs = 50\n",
    "learning_rate = 0.1\n",
    "\n",
    "train(epochs, learning_rate)\n",
    "\n",
    "# 进行测试\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8529b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save({'w': w, 'b': b}, 'Classification_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecbb5a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.4445, Accuracy: 0.8525\n",
      "Epoch [2/50], Loss: 0.4437, Accuracy: 0.8516\n",
      "Epoch [3/50], Loss: 0.4430, Accuracy: 0.8517\n",
      "Epoch [4/50], Loss: 0.4404, Accuracy: 0.8531\n",
      "Epoch [5/50], Loss: 0.4378, Accuracy: 0.8537\n",
      "Epoch [6/50], Loss: 0.4393, Accuracy: 0.8530\n",
      "Epoch [7/50], Loss: 0.4368, Accuracy: 0.8535\n",
      "Epoch [8/50], Loss: 0.4351, Accuracy: 0.8549\n",
      "Epoch [9/50], Loss: 0.4330, Accuracy: 0.8549\n",
      "Epoch [10/50], Loss: 0.4315, Accuracy: 0.8553\n",
      "Epoch [11/50], Loss: 0.4301, Accuracy: 0.8559\n",
      "Epoch [12/50], Loss: 0.4295, Accuracy: 0.8555\n",
      "Epoch [13/50], Loss: 0.4274, Accuracy: 0.8559\n",
      "Epoch [14/50], Loss: 0.4276, Accuracy: 0.8547\n",
      "Epoch [15/50], Loss: 0.4259, Accuracy: 0.8566\n",
      "Epoch [16/50], Loss: 0.4234, Accuracy: 0.8568\n",
      "Epoch [17/50], Loss: 0.4241, Accuracy: 0.8559\n",
      "Epoch [18/50], Loss: 0.4227, Accuracy: 0.8573\n",
      "Epoch [19/50], Loss: 0.4227, Accuracy: 0.8572\n",
      "Epoch [20/50], Loss: 0.4209, Accuracy: 0.8564\n",
      "Epoch [21/50], Loss: 0.4193, Accuracy: 0.8573\n",
      "Epoch [22/50], Loss: 0.4187, Accuracy: 0.8587\n",
      "Epoch [23/50], Loss: 0.4197, Accuracy: 0.8565\n",
      "Epoch [24/50], Loss: 0.4182, Accuracy: 0.8578\n",
      "Epoch [25/50], Loss: 0.4149, Accuracy: 0.8583\n",
      "Epoch [26/50], Loss: 0.4134, Accuracy: 0.8600\n",
      "Epoch [27/50], Loss: 0.4142, Accuracy: 0.8590\n",
      "Epoch [28/50], Loss: 0.4132, Accuracy: 0.8584\n",
      "Epoch [29/50], Loss: 0.4135, Accuracy: 0.8575\n",
      "Epoch [30/50], Loss: 0.4101, Accuracy: 0.8604\n",
      "Epoch [31/50], Loss: 0.4116, Accuracy: 0.8585\n",
      "Epoch [32/50], Loss: 0.4098, Accuracy: 0.8604\n",
      "Epoch [33/50], Loss: 0.4103, Accuracy: 0.8600\n",
      "Epoch [34/50], Loss: 0.4079, Accuracy: 0.8607\n",
      "Epoch [35/50], Loss: 0.4090, Accuracy: 0.8600\n",
      "Epoch [36/50], Loss: 0.4070, Accuracy: 0.8606\n",
      "Epoch [37/50], Loss: 0.4073, Accuracy: 0.8604\n",
      "Epoch [38/50], Loss: 0.4056, Accuracy: 0.8612\n",
      "Epoch [39/50], Loss: 0.4056, Accuracy: 0.8615\n",
      "Epoch [40/50], Loss: 0.4052, Accuracy: 0.8609\n",
      "Epoch [41/50], Loss: 0.4044, Accuracy: 0.8616\n",
      "Epoch [42/50], Loss: 0.4042, Accuracy: 0.8615\n",
      "Epoch [43/50], Loss: 0.4048, Accuracy: 0.8607\n",
      "Epoch [44/50], Loss: 0.4034, Accuracy: 0.8610\n",
      "Epoch [45/50], Loss: 0.4028, Accuracy: 0.8616\n",
      "Epoch [46/50], Loss: 0.4011, Accuracy: 0.8614\n",
      "Epoch [47/50], Loss: 0.4020, Accuracy: 0.8627\n",
      "Epoch [48/50], Loss: 0.3997, Accuracy: 0.8622\n",
      "Epoch [49/50], Loss: 0.3992, Accuracy: 0.8628\n",
      "Epoch [50/50], Loss: 0.4004, Accuracy: 0.8621\n",
      "Test Loss: 0.5032, Test Accuracy: 0.8341\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "checkpoint = torch.load('Classification_model.pth')\n",
    "\n",
    "# 下载训练集和测试集\n",
    "train_dataset = FashionMNIST(root='data/', train=True, transform=ToTensor(), download=True)\n",
    "test_dataset = FashionMNIST(root='data/', train=False, transform=ToTensor(), download=True)\n",
    "\n",
    "# 创建训练集和测试集的数据加载器\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# 初始化模型参数\n",
    "num_features = 28 * 28  # 输入特征的数量（图像大小为28x28）\n",
    "num_classes = 10  # 类别数量\n",
    "w = checkpoint['w']\n",
    "b = checkpoint['b']\n",
    "# 设置训练参数并开始训练\n",
    "epochs = 50\n",
    "learning_rate = 0.1\n",
    "\n",
    "train(epochs, learning_rate)\n",
    "\n",
    "# 进行测试\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ccd9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save({'w': w, 'b': b}, 'Classification_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cebee632",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     20\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 进行测试\u001b[39;00m\n\u001b[1;32m     25\u001b[0m test()\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, learning_rate)\u001b[0m\n\u001b[1;32m      5\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m total_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_images, batch_labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m      8\u001b[0m     batch_images \u001b[38;5;241m=\u001b[39m batch_images\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_features)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_11/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_11/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_11/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_11/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_11/lib/python3.8/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_11/lib/python3.8/site-packages/torchvision/transforms/transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda_11/lib/python3.8/site-packages/torchvision/transforms/functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    167\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[0;32m--> 168\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbands\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m    170\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "checkpoint = torch.load('Classification_model.pth')\n",
    "\n",
    "# 下载训练集和测试集\n",
    "train_dataset = FashionMNIST(root='data/', train=True, transform=ToTensor(), download=True)\n",
    "test_dataset = FashionMNIST(root='data/', train=False, transform=ToTensor(), download=True)\n",
    "\n",
    "# 创建训练集和测试集的数据加载器\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# 初始化模型参数\n",
    "num_features = 28 * 28  # 输入特征的数量（图像大小为28x28）\n",
    "num_classes = 10  # 类别数量\n",
    "w = checkpoint['w']\n",
    "b = checkpoint['b']\n",
    "# 设置训练参数并开始训练\n",
    "epochs = 50\n",
    "learning_rate = 0.1\n",
    "\n",
    "train(epochs, learning_rate)\n",
    "\n",
    "# 进行测试\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d896d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71f414f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7056,  3.6875,  1.1252,  ..., -0.0564, -0.7181, -0.7160],\n",
       "        [-1.0933, -0.2097, -0.3350,  ...,  0.5351,  1.9643, -0.1643],\n",
       "        [ 1.0277, -1.7061, -1.8516,  ...,  0.5984, -0.3432, -0.4054],\n",
       "        ...,\n",
       "        [-0.2210,  1.4967,  0.6180,  ..., -1.0178, -0.8755,  0.7527],\n",
       "        [-0.8656,  0.2825, -0.6440,  ..., -0.5004, -0.3248,  0.5127],\n",
       "        [-0.4026, -1.1222,  1.7200,  ...,  0.3806, -1.2070,  1.0543]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4556262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
