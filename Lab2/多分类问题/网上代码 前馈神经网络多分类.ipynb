{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd07e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bcbdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transformation =transforms.Compose([\n",
    "    transforms.ToTensor()  #转换到Tensor，并且转换为0-1之间,将channel 放到第一个纬度\n",
    "])\n",
    "train_ds = datasets.MNIST('data/',train = True,transform = transformation,download = True)\n",
    "test_ds = datasets.MNIST('data/',train = False,transform = transformation,download = True)\n",
    "# len(train_ds)\n",
    "# len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d27eaddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds,batch_size =64 ,shuffle = True,num_workers = 16)\n",
    "test_loader = DataLoader(test_ds,batch_size =256 ,shuffle = False,num_workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea503e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(28*28,128)\n",
    "        self.linear2 = nn.Linear(128,64)\n",
    "        self.linear3 = nn.Linear(64,10)\n",
    "    def forward(self,input):\n",
    "        x = input.view(-1,28*28)\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        y = self.linear3(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ca5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "loss_fn  = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b2489c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_true):\n",
    "    y_pred = torch.argmax(y_pred,dim=1)\n",
    "    acc = (y_pred==y_true).float().mean()\n",
    "    return acc\n",
    "#测试集\n",
    "def evaluate_testset(data_loader,model):\n",
    "    acc_sum,loss_sum,total_example = 0.0,0.0,0\n",
    "    for x,y in data_loader:\n",
    "        y_hat = model(x)\n",
    "        acc_sum += (y_hat.argmax(dim=1)==y).sum().item()\n",
    "        loss = loss_fn(y_hat,y) \n",
    "        loss_sum += loss.item()\n",
    "        total_example+=y.shape[0]\n",
    "    return acc_sum/total_example,loss_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bb7894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型训练函数\n",
    "def train(model,train_loader,test_loader,loss,num_epochs,batch_size,params=None,lr=None,optimizer=None):\n",
    "    train_ls = []\n",
    "    test_ls = []\n",
    "    for epoch in range(num_epochs): # 训练模型一共需要num_epochs个迭代周期\n",
    "        train_loss_sum, train_acc_num,total_examples = 0.0,0.0,0\n",
    "        for x, y in train_loader: # x和y分别是小批量样本的特征和标签\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)  #计算损失\n",
    "            optimizer.zero_grad() # 梯度清零\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step() #梯度更新\n",
    "            total_examples += y.shape[0]\n",
    "            train_loss_sum += loss.item()\n",
    "            train_acc_num += (y_pred.argmax(dim=1)==y).sum().item()\n",
    "        train_ls.append(train_loss_sum)\n",
    "        test_acc,test_loss = evaluate_testset(test_loader,model)\n",
    "        test_ls.append(test_loss)\n",
    "        print('epoch %d, train_loss %.6f,test_loss %f,train_acc %.6f,test_acc %.6f'%(epoch+1, train_ls[epoch],test_ls[epoch],train_acc_num/total_examples,test_acc))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b01869cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch  = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae545708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train_loss 321.557572,test_loss 7.031791,train_acc 0.902517,test_acc 0.945500\n",
      "epoch 2, train_loss 134.737983,test_loss 4.530779,train_acc 0.956817,test_acc 0.963900\n",
      "epoch 3, train_loss 94.064229,test_loss 3.816852,train_acc 0.969617,test_acc 0.970000\n",
      "epoch 4, train_loss 70.966020,test_loss 3.390277,train_acc 0.976150,test_acc 0.971100\n",
      "epoch 5, train_loss 56.267231,test_loss 3.210675,train_acc 0.981400,test_acc 0.974300\n",
      "epoch 6, train_loss 44.219717,test_loss 3.130155,train_acc 0.985533,test_acc 0.974600\n",
      "epoch 7, train_loss 37.977134,test_loss 4.064653,train_acc 0.986833,test_acc 0.968400\n",
      "epoch 8, train_loss 31.329893,test_loss 3.400227,train_acc 0.989317,test_acc 0.973800\n",
      "epoch 9, train_loss 25.581067,test_loss 3.188283,train_acc 0.991350,test_acc 0.976400\n",
      "epoch 10, train_loss 20.659922,test_loss 3.035384,train_acc 0.993033,test_acc 0.978300\n",
      "epoch 11, train_loss 18.156700,test_loss 3.157790,train_acc 0.993550,test_acc 0.977800\n",
      "epoch 12, train_loss 17.092509,test_loss 3.213999,train_acc 0.994017,test_acc 0.979000\n",
      "epoch 13, train_loss 14.840480,test_loss 3.722929,train_acc 0.994650,test_acc 0.975900\n",
      "epoch 14, train_loss 11.275421,test_loss 3.523051,train_acc 0.996033,test_acc 0.978000\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,test_loader,loss_fn,num_epoch,batch_size,params=model.parameters,lr=0.001,optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
